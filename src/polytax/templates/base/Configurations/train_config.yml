run_training: True
run_evaluation: False
seed: 12345

# Multi-host
distributed:
  backend: "GLOO" # use NCCL for GPU

dataset:
  kwargs:
    name: "c4.en" # "glue_cola_v002"
    split: "train"
    max_seq_length: 512
    batch_size: 8
    use_iterable_ds: True

#dataset:
#  kwargs:
#    name: "glue_v002_proportional" # "glue_cola_v002"
#    split: "validation"
#    max_seq_length: 32
#    batch_size: 4
#    use_iterable_ds: True

# Optimizer
optim:
  name: "Adafactor"
  kwargs:
    clip_threshold: 1.0
    decay_rate: -0.8
    weight_decay: 0.0
    relative_step: True
    scale_parameter: True
    warmup_init: True


# Steps
training:
  checkpoint_every: 100

# Steps
wandb:
  log_scalars_every: 10

log_every: 200
checkpoint_every: 10000
valid_every: 50
num_train_steps: 1000000

# Logging
use_wandb: True

# Model Config
model_config:
  d_ff: 3072
  d_kv: 64
  d_model: 768
  decoder_start_token_id: 0
  dropout_rate: 0.1
  eos_token_id: 1
  feed_forward_proj: "relu"
  gradient_checkpointing: "False"
  initializer_factor: 1.0
  is_encoder_decoder: "True"
  layer_norm_epsilon: 1e-6
  model_type: "t5"
  num_decoder_layers: 12
  num_heads: 12
  num_layers: 12
  pad_token_id: 0
  relative_attention_num_buckets: 32
  transformers_version: "4.10.0.dev0"
  use_cache: false
  cache_dir: "/tmp/"
  vocab_size: 32003


tpu:
  kwargs:
    bucket: "must-results"
    zone: "us-central1-f"
    network: "tpu-network"
    subnet: "swarm-2"
    netrange: "192.169.0.0/29"
    acc_type: "v2-8"
    preemptible: False
#    name: "node-3"